# @package callbacks

# This callback is for iterative training runs on time-limited partitions.
# It saves the last checkpoint frequently, allowing the next job to resume.
- _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: "checkpoints/"
  # The 'save_last' option creates a 'last.ckpt' symlink, which is perfect for resuming.
  save_last: true
  # We can still save the best model based on loss if we want.
  monitor: "train/loss"
  mode: "min"
  save_top_k: 1
  # Save a checkpoint based on the number of training steps.
  every_n_train_steps: 20
  # Explicitly disable saving at the end of an epoch. We only want step-based saving.
  save_on_train_epoch_end: false
  # The filename for the best model checkpoint. 'last.ckpt' will be handled automatically.
  filename: "best-epoch={epoch}-step={step}"