defaults:
  - _self_
  - model: gpt2-large
  - reward: deberta_v3
  - logger: wandb
  # --- REVERTED: Back to a simple default. The run scripts will override this. ---
  - callbacks: model_checkpoint
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

seed: 42

data:
  path: "data/zsre_1000.jsonl"
  train_size: 0.9
  limit_data: null
  num_workers: 2

buffer:
  redis_host: "localhost"
  redis_port: 6379

training:
  lr: 1e-4
  epochs: 10
  accumulate_grad_batches: 8
  # --- For this stable version, let's keep logging frequent ---
  log_every_n_steps: 1


trainer:
  accelerator: "gpu"
  strategy: "auto"
  devices: 1
  num_nodes: 1
  max_epochs: 10 # Set the default here

task:
  task_prompt: "Generate a question about {subject}:\nQuestion:"
  answer_prompt_template: |
    Rephrase the question into a complete, declarative sentence that provides the answer.

    Example 1:
    Question: Which country is Paris the capital of?
    Answer: The capital of France is Paris.

    Example 2:
    Question: What is the main component of Earth's atmosphere?
    Answer: The main component of Earth's atmosphere is Nitrogen.

    Example 3:
    Question: Who wrote the play 'Hamlet'?
    Answer: The play 'Hamlet' was written by William Shakespeare.

    Question: {question}
    Answer:

  likelihood_weight: 0.2
  n_samples: 8
  min_question_len: 5
  max_question_len: 25
  subtb_lambda: 1.0
  pf_temp_prob: 0.5
  pf_temp_low: 0.7
  pf_temp_high: 1.5
  use_buffer_prob: 0.5
  replay_buffer_size: 128
  reward_temp_start: 1.0
  reward_temp_end: 2.0
  reward_temp_horizon: 2000
  n_probes: 5
  checkpoint_save_interval: 200
  
  # --- Hybrid Reward Parameters ---
  use_hybrid_reward: true
  penalized_reward_end_step: 150
  contradiction_threshold: -6.0
  failure_penalty: -50.0

  # --- NEW: Parameters for Answer Quality Reward Component ---
  answer_quality_weight: 0.0       # Weight for the answer likelihood score. Set to 0.0 to disable.
  answer_quality_threshold: -20.0  # Log-likelihood threshold below which answers are considered "low quality".
  answer_failure_penalty: 0.0    # Penalty to apply to the reward for low-quality answers.


logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  project: "contradiction-gfn"
  name: null
  group: null
  log_model: false
  mode: offline

hydra:
  job:
    chdir: False